{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ = pd.read_csv('articles_community.csv')\n",
    "interactions_ = pd.read_csv('user-item-interactions.csv')\n",
    "del articles_['Unnamed: 0']\n",
    "del interactions_['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Exploratory Data Analysis\n",
    "\n",
    "Take a look at the data and use your findings to fill in the dictionary below with the correct responses to show your understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>Live</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>Live</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>Live</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  \\\n",
       "0  Detect bad readings in real time using Python ...   \n",
       "1  See the forest, see the trees. Here lies the c...   \n",
       "2  Here’s this week’s news in Data Science and Bi...   \n",
       "3  Learn how distributed DBs solve the problem of...   \n",
       "4  This video demonstrates the power of IBM DataS...   \n",
       "\n",
       "                                       doc_full_name doc_status  article_id  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...       Live           0  \n",
       "1  Communicating data science: A guide to present...       Live           1  \n",
       "2         This Week in Data Science (April 18, 2017)       Live           2  \n",
       "3  DataLayer Conference: Boost the performance of...       Live           3  \n",
       "4      Analyze NY Restaurant data using Spark in DSX       Live           4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of articles is 1056.\n",
      "The number of interactions is 45993.\n",
      "The number of unique users is 5148.\n",
      "The number of missing interactions is 17.\n"
     ]
    }
   ],
   "source": [
    "# number of movies\n",
    "print(\"The number of articles is {}.\".format(articles_.shape[0]))\n",
    "\n",
    "# number of ratings\n",
    "print(\"The number of interactions is {}.\".format(interactions_.shape[0]))\n",
    "\n",
    "# unique users\n",
    "print(\"The number of unique users is {}.\".format(interactions_.email.nunique()))\n",
    "\n",
    "# missing interactions\n",
    "print(\"The number of missing interactions is {}.\".format(int(interactions_.email.isnull().mean()*interactions_.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45988</th>\n",
       "      <td>1324.0</td>\n",
       "      <td>ibm watson facebook posts for 2015</td>\n",
       "      <td>d21b998d7a4722310ceeaa3c6aaa181a36db2d73</td>\n",
       "      <td>5146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45989</th>\n",
       "      <td>142.0</td>\n",
       "      <td>neural networks for beginners: popular types a...</td>\n",
       "      <td>d21b998d7a4722310ceeaa3c6aaa181a36db2d73</td>\n",
       "      <td>5146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45990</th>\n",
       "      <td>233.0</td>\n",
       "      <td>bayesian nonparametric models – stats and bots</td>\n",
       "      <td>4faeed980a7cd11e0f3cf2058cc04daa2ef11452</td>\n",
       "      <td>5147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45991</th>\n",
       "      <td>1160.0</td>\n",
       "      <td>analyze accident reports on amazon emr spark</td>\n",
       "      <td>abbf639ba05daa5249c520e290283a6d726ba78d</td>\n",
       "      <td>5148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45992</th>\n",
       "      <td>16.0</td>\n",
       "      <td>higher-order logistic regression for large dat...</td>\n",
       "      <td>1f18e8aaccd6c8720180c3fe264c8aef5b00697f</td>\n",
       "      <td>5149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45993 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                              title  \\\n",
       "0          1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1          1314.0       healthcare python streaming application demo   \n",
       "2          1429.0         use deep learning for image classification   \n",
       "3          1338.0          ml optimization using cognitive assistant   \n",
       "4          1276.0          deploy your python model as a restful api   \n",
       "...           ...                                                ...   \n",
       "45988      1324.0                 ibm watson facebook posts for 2015   \n",
       "45989       142.0  neural networks for beginners: popular types a...   \n",
       "45990       233.0     bayesian nonparametric models – stats and bots   \n",
       "45991      1160.0       analyze accident reports on amazon emr spark   \n",
       "45992        16.0  higher-order logistic regression for large dat...   \n",
       "\n",
       "                                          email  user_id  \n",
       "0      ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7        1  \n",
       "1      083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b        2  \n",
       "2      b96a4f2e92d8572034b1e9b28f9ac673765cd074        3  \n",
       "3      06485706b34a5c9bf2a0ecdac41daf7e7654ceb7        4  \n",
       "4      f01220c46fc92c6e6b161b1849de11faacd7ccb2        5  \n",
       "...                                         ...      ...  \n",
       "45988  d21b998d7a4722310ceeaa3c6aaa181a36db2d73     5146  \n",
       "45989  d21b998d7a4722310ceeaa3c6aaa181a36db2d73     5146  \n",
       "45990  4faeed980a7cd11e0f3cf2058cc04daa2ef11452     5147  \n",
       "45991  abbf639ba05daa5249c520e290283a6d726ba78d     5148  \n",
       "45992  1f18e8aaccd6c8720180c3fe264c8aef5b00697f     5149  \n",
       "\n",
       "[45993 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## No need to change the code here - this will be helpful for later parts of the notebook\n",
    "# Run this cell to map the user email to a user_id column and remove the email column\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = {}\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in interactions_['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "#del interactions['email']\n",
    "interactions_['user_id'] = email_encoded\n",
    "\n",
    "# show header\n",
    "interactions_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2b6c0f514c2f2b04ad3c4583407dccd0810469ee    364\n",
       "77959baaa9895a7e2bdc9297f8b27c1b6f2cb52a    363\n",
       "2f5c7feae533ce046f2cb16fb3a29fe00528ed66    170\n",
       "a37adec71b667b297ed2440a9ff7dad427c7ac85    169\n",
       "8510a5010a5d4c89f5b07baac6de80cd12cfaf93    160\n",
       "                                           ... \n",
       "308db8b36ed6a332c2eba4db83f73d2ef9161d64      1\n",
       "0e42ebc8e6a6d26a3adc4fa7684db69aaabe01e5      1\n",
       "98247b6240b3831804b0e04f341fc77517a2caf7      1\n",
       "8ff6bfc629e1eb4f9160a6b1d5aa25c171dbbbb1      1\n",
       "d48906d5eb86921deb4bd075a68dbb32690b1fa6      1\n",
       "Name: email, Length: 5148, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_.email.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>362.0</td>\n",
       "      <td>dsx: hybrid mode</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>409.0</td>\n",
       "      <td>using github for project control in dsx</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>409.0</td>\n",
       "      <td>using github for project control in dsx</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>302.0</td>\n",
       "      <td>accelerate your workflow with dsx</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>409.0</td>\n",
       "      <td>using github for project control in dsx</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23976</th>\n",
       "      <td>1162.0</td>\n",
       "      <td>analyze energy consumption in buildings</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24384</th>\n",
       "      <td>1162.0</td>\n",
       "      <td>analyze energy consumption in buildings</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24622</th>\n",
       "      <td>236.0</td>\n",
       "      <td>improving real-time object detection with yolo</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24750</th>\n",
       "      <td>302.0</td>\n",
       "      <td>accelerate your workflow with dsx</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24844</th>\n",
       "      <td>1360.0</td>\n",
       "      <td>pixieapp for outlier detection</td>\n",
       "      <td>2b6c0f514c2f2b04ad3c4583407dccd0810469ee</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       article_id                                           title  \\\n",
       "28          362.0                                dsx: hybrid mode   \n",
       "72          409.0         using github for project control in dsx   \n",
       "97          409.0         using github for project control in dsx   \n",
       "223         302.0               accelerate your workflow with dsx   \n",
       "255         409.0         using github for project control in dsx   \n",
       "...           ...                                             ...   \n",
       "23976      1162.0         analyze energy consumption in buildings   \n",
       "24384      1162.0         analyze energy consumption in buildings   \n",
       "24622       236.0  improving real-time object detection with yolo   \n",
       "24750       302.0               accelerate your workflow with dsx   \n",
       "24844      1360.0                  pixieapp for outlier detection   \n",
       "\n",
       "                                          email  user_id  \n",
       "28     2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "72     2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "97     2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "223    2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "255    2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "...                                         ...      ...  \n",
       "23976  2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "24384  2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "24622  2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "24750  2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "24844  2b6c0f514c2f2b04ad3c4583407dccd0810469ee       23  \n",
       "\n",
       "[364 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_[interactions_.email=='2b6c0f514c2f2b04ad3c4583407dccd0810469ee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330.0</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1431.0</td>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1427.0</td>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1364.0</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1113.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>984.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>1266.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id  title  email  user_id\n",
       "0        1429.0    937    937      937\n",
       "1        1330.0    927    927      927\n",
       "2        1431.0    671    671      671\n",
       "3        1427.0    643    643      643\n",
       "4        1364.0    627    627      627\n",
       "..          ...    ...    ...      ...\n",
       "709      1113.0      1      1        1\n",
       "710      1119.0      1      1        1\n",
       "711       984.0      1      1        1\n",
       "712      1127.0      1      1        1\n",
       "713      1266.0      1      1        1\n",
       "\n",
       "[714 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_interactions=interactions_.groupby('article_id').count().sort_values('user_id', ascending=False).reset_index()\n",
    "describe_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique users is :  5149\n",
      "The maximum article across all interactions is:  1444.0\n",
      "The average article across all interactions is:  64.0\n",
      "The minimum article across all interactions is:  1\n",
      "The number of missing interactions is:  17\n",
      "The number of articles in the dataset:  1056\n",
      "The number of interactions in the dataset:  45993\n"
     ]
    }
   ],
   "source": [
    "print('The number of unique users is : ',interactions_.user_id.nunique())\n",
    "print('The maximum article across all interactions is: ',describe_interactions.max()['article_id'])\n",
    "print('The average article across all interactions is: ',np.round(describe_interactions.user_id.mean(), 0))\n",
    "print('The minimum article across all interactions is: ',describe_interactions.user_id.min())\n",
    "print('The number of missing interactions is: ',int(interactions_.email.isnull().mean()*interactions_.shape[0]))\n",
    "print('The number of articles in the dataset: ',articles_.shape[0])\n",
    "print('The number of interactions in the dataset: ',interactions_.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(articles_.article_id.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_.drop_duplicates(subset='article_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(articles_.article_id.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Rank Based Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. How To Find The Most Popular articles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>doc_full_name</th>\n",
       "      <th>doc_status</th>\n",
       "      <th>avg_interaction</th>\n",
       "      <th>num_interactions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video shows you how to set up connections...</td>\n",
       "      <td>Work with Data Connections in DSX</td>\n",
       "      <td>Live</td>\n",
       "      <td>4109.285714</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Homepage Stats and Bots Follow Sign in / Sign ...</td>\n",
       "      <td>An introduction to Bayesian Nonparametrics: th...</td>\n",
       "      <td>Bayesian Nonparametric Models – Stats and Bots</td>\n",
       "      <td>Live</td>\n",
       "      <td>4021.125000</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jump to navigation\\r\\n\\r\\n * Twitter\\r\\n * Lin...</td>\n",
       "      <td>Discover an open source machine learning platf...</td>\n",
       "      <td>Improving quality of life with Spark-empowered...</td>\n",
       "      <td>Live</td>\n",
       "      <td>3952.428571</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RStudio Blog * Home\\r\\n\\r\\n * Subscribe to fee...</td>\n",
       "      <td>readr 1.0.0 is now available on CRAN. readr ma...</td>\n",
       "      <td>readr 1.0.0</td>\n",
       "      <td>Live</td>\n",
       "      <td>3914.812500</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>* Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...</td>\n",
       "      <td>This post provides a brief summary of sample c...</td>\n",
       "      <td>Apache Spark™ 2.0: Migrating Applications</td>\n",
       "      <td>Live</td>\n",
       "      <td>3911.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>Although it is built around a JavaScript engin...</td>\n",
       "      <td>How I Stopped Worrying &amp; Learned to Love the M...</td>\n",
       "      <td>Live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Margriet Groenendijk Blocked Unblock Follow Fo...</td>\n",
       "      <td>Last week I attended the GeoPython conference ...</td>\n",
       "      <td>Mapping All the Things with Python – IBM Watso...</td>\n",
       "      <td>Live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...</td>\n",
       "      <td>Lua is a compact language which can be embedde...</td>\n",
       "      <td>A Speed Guide To Redis Lua Scripting</td>\n",
       "      <td>Live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>PouchDB-find is a new API and syntax that allo...</td>\n",
       "      <td>PouchDB uses MapReduce as its default search m...</td>\n",
       "      <td>A look under the covers of PouchDB-find</td>\n",
       "      <td>Live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Learn how to use IBM dashDB as data store for ...</td>\n",
       "      <td>Use dashDB with Spark</td>\n",
       "      <td>Live</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     doc_body  \\\n",
       "article_id                                                      \n",
       "277         Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "233         Homepage Stats and Bots Follow Sign in / Sign ...   \n",
       "96          Jump to navigation\\r\\n\\r\\n * Twitter\\r\\n * Lin...   \n",
       "60          RStudio Blog * Home\\r\\n\\r\\n * Subscribe to fee...   \n",
       "117         * Home\\r\\n * Community\\r\\n * Projects\\r\\n * Bl...   \n",
       "...                                                       ...   \n",
       "1040        Although it is built around a JavaScript engin...   \n",
       "1041        Margriet Groenendijk Blocked Unblock Follow Fo...   \n",
       "1045        lA SPEED GUIDE TO REDIS LUA SCRIPTING\\r\\nShare...   \n",
       "1046        PouchDB-find is a new API and syntax that allo...   \n",
       "1049                                                      NaN   \n",
       "\n",
       "                                              doc_description  \\\n",
       "article_id                                                      \n",
       "277         This video shows you how to set up connections...   \n",
       "233         An introduction to Bayesian Nonparametrics: th...   \n",
       "96          Discover an open source machine learning platf...   \n",
       "60          readr 1.0.0 is now available on CRAN. readr ma...   \n",
       "117         This post provides a brief summary of sample c...   \n",
       "...                                                       ...   \n",
       "1040        Although it is built around a JavaScript engin...   \n",
       "1041        Last week I attended the GeoPython conference ...   \n",
       "1045        Lua is a compact language which can be embedde...   \n",
       "1046        PouchDB uses MapReduce as its default search m...   \n",
       "1049        Learn how to use IBM dashDB as data store for ...   \n",
       "\n",
       "                                                doc_full_name doc_status  \\\n",
       "article_id                                                                 \n",
       "277                         Work with Data Connections in DSX       Live   \n",
       "233            Bayesian Nonparametric Models – Stats and Bots       Live   \n",
       "96          Improving quality of life with Spark-empowered...       Live   \n",
       "60                                                readr 1.0.0       Live   \n",
       "117                 Apache Spark™ 2.0: Migrating Applications       Live   \n",
       "...                                                       ...        ...   \n",
       "1040        How I Stopped Worrying & Learned to Love the M...       Live   \n",
       "1041        Mapping All the Things with Python – IBM Watso...       Live   \n",
       "1045                     A Speed Guide To Redis Lua Scripting       Live   \n",
       "1046                  A look under the covers of PouchDB-find       Live   \n",
       "1049                                    Use dashDB with Spark       Live   \n",
       "\n",
       "            avg_interaction  num_interactions  \n",
       "article_id                                     \n",
       "277             4109.285714              14.0  \n",
       "233             4021.125000              16.0  \n",
       "96              3952.428571               7.0  \n",
       "60              3914.812500              16.0  \n",
       "117             3911.000000              10.0  \n",
       "...                     ...               ...  \n",
       "1040                    NaN               NaN  \n",
       "1041                    NaN               NaN  \n",
       "1045                    NaN               NaN  \n",
       "1046                    NaN               NaN  \n",
       "1049                    NaN               NaN  \n",
       "\n",
       "[1051 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_interactions = interactions_.groupby('article_id')['user_id']\n",
    "avg_interactions = article_interactions.mean()\n",
    "num_interactions = article_interactions.count()\n",
    "title = pd.DataFrame(interactions_.title.value_counts()).reset_index()\n",
    "# Add Dates\n",
    "interaction_count_df = pd.DataFrame({'avg_interaction': avg_interactions, 'num_interactions': num_interactions})\n",
    "#interaction_count_df = interaction_count_df.join(title)\n",
    "\n",
    "article_recs = articles_.set_index('article_id').join(interaction_count_df)\n",
    "\n",
    "# sort by top avg interaction and number of interactions\n",
    "article_recs.sort_values(['avg_interaction', 'num_interactions'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ranked_df(articles_, interactions_):\n",
    "        '''\n",
    "        INPUT\n",
    "        movies - the articles dataframe\n",
    "        reviews - the interactions dataframe\n",
    "        \n",
    "        OUTPUT\n",
    "        ranked_articles - a dataframe with articles that are sorted by highest avg rating, more reviews\n",
    "        and must have more than 4 ratings\n",
    "        '''\n",
    "        \n",
    "        # Pull the average interactions and number of interactions for each article\n",
    "        article_interactions = interactions_.groupby('article_id')['user_id']\n",
    "        avg_interactions = article_interactions.mean()\n",
    "        num_interactions = article_interactions.count()\n",
    "        \n",
    "        # Add Dates\n",
    "        interaction_count_df = pd.DataFrame({'avg_interaction': avg_interactions, 'num_interactions': num_interactions})\n",
    "        \n",
    "        # merge with the movies dataset\n",
    "        article_recs = articles_.set_index('article_id').join(interaction_count_df)\n",
    "\n",
    "        # sort by top avg interaction and number of interactions\n",
    "        ranked_articles = article_recs.sort_values(['avg_interaction', 'num_interactions'], ascending=False)\n",
    "\n",
    "        # for edge cases - subset the article list to those with only 5 or more interactions\n",
    "        ranked_articles = ranked_articles[ranked_articles['num_interactions'] > 4]\n",
    "        \n",
    "        return ranked_articles\n",
    "    \n",
    "\n",
    "def popular_recommendations(user_id, n_top, ranked_articles):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id (str) of the individual you are making recommendations for\n",
    "    n_top - an integer of the number recommendations you want back\n",
    "    ranked_articles - a pandas dataframe of the already ranked articles based on avg rating, count, and time\n",
    "\n",
    "    OUTPUT:\n",
    "    top_articles - a list of the n_top recommended articles by article doc_full_name in order best to worst\n",
    "    '''\n",
    "\n",
    "    top_articles = list(ranked_articles['doc_full_name'][:n_top])\n",
    "\n",
    "    return top_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_articles = create_ranked_df(articles_, interactions_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Work with Data Connections in DSX',\n",
       " 'Bayesian Nonparametric Models – Stats and Bots',\n",
       " 'Improving quality of life with Spark-empowered machine learning',\n",
       " 'readr 1.0.0',\n",
       " 'Apache Spark™ 2.0: Migrating Applications',\n",
       " 'Data science expert interview: Holden Karau',\n",
       " 'Top analytics tools in 2016',\n",
       " 'Data Science of Variable Selection',\n",
       " 'Build a logistic regression model with WML & DSX',\n",
       " 'Apache Spark @Scale: A 60 TB+ production use case',\n",
       " 'Join and enrich data from multiple sources',\n",
       " 'This Week in Data Science (July 26, 2016)',\n",
       " 'Use data assets in a project using IBM Data Catalog',\n",
       " 'Advancements in the Spark Community',\n",
       " 'This Week in Data Science (November 01, 2016)',\n",
       " 'xml2 1.0.0',\n",
       " 'A guide to receptive field arithmetic for Convolutional Neural Networks',\n",
       " 'Foundational Methodology for Data Science',\n",
       " 'Finding the user in data science',\n",
       " '3 Scenarios for Machine Learning on Multicloud']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 20 movies recommended for id 1\n",
    "recs_20_for_1 = popular_recommendations('1', 20, ranked_articles)\n",
    "recs_20_for_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['use deep learning for image classification',\n",
       " 'insights from new york car accident reports',\n",
       " 'visualize car data with brunel',\n",
       " 'use xgboost, scikit-learn & ibm watson machine learning apis',\n",
       " 'predicting churn with the spss random tree algorithm',\n",
       " 'healthcare python streaming application demo',\n",
       " 'finding optimal locations of new store using decision optimization',\n",
       " 'apache spark lab, part 1: basic concepts',\n",
       " 'analyze energy consumption in buildings',\n",
       " 'gosales transactions for logistic regression model',\n",
       " 'welcome to pixiedust',\n",
       " 'customer demographics and sales',\n",
       " 'total population by country',\n",
       " 'deep learning with tensorflow course by big data university',\n",
       " 'model bike sharing data with spss',\n",
       " 'the nurse assignment problem',\n",
       " 'classify tumors with machine learning',\n",
       " 'analyze accident reports on amazon emr spark',\n",
       " 'movie recommender system with spark machine learning',\n",
       " 'putting a human face on machine learning']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 20 movies recommended by title\n",
    "list(interactions_.groupby(by='title').count().sort_values(by='user_id', ascending=False).head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 movies recommended for id 53968\n",
    "recs_5_for_53968 = popular_recommendations('53968', 5, ranked_articles)\n",
    "\n",
    "# Top 100 movies recommended for id 70000\n",
    "recs_100_for_70000 = popular_recommendations('70000', 100, ranked_articles)\n",
    "\n",
    "# Top 35 movies recommended for id 43\n",
    "recs_35_for_43 = popular_recommendations('43', 35, ranked_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part II: Adding Filters\n",
    "Now that you have created a function to give back the title articles Who are we looking for, let's make it a bit more robust. Add arguments that will act as filters for the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recs_filtered(formal_ed_str,lookfor=None):\n",
    "    '''\n",
    "    INPUT\n",
    "        formal_ed_str - a string of one of the values from the title column\n",
    "        lookfor - list of string Who are we looking for\n",
    "    \n",
    "    OUTPUT\n",
    "        return res if the string is in lookfor\n",
    "        return 0 otherwise\n",
    "    \n",
    "    '''\n",
    "    if lookfor is not None:\n",
    "        res = [formal_ed_str for x in lookfor if x in formal_ed_str] \n",
    "        if res:\n",
    "            return res\n",
    "        else:\n",
    "            return 0\n",
    "    return formal_ed_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Improving quality of life with Spark-empowered machine learning']\n",
      "['8 ways to turn data into value with Apache Spark machine learning']\n",
      "['Apple, IBM add machine learning to partnership with Watson-Core ML coupling']\n",
      "['Lifelong (machine) learning: how automation can help your models get smarter over time']\n"
     ]
    }
   ],
   "source": [
    "articles=[]\n",
    "# Top 100 articles recommended for id 70000 with titles=[machine'] filter\n",
    "recs_100_for_70000 = popular_recommendations('70000', 100, ranked_articles)\n",
    "for i in recs_100_for_70000:\n",
    "    recs_filtered_list=recs_filtered(i,['machine'])\n",
    "    if recs_filtered_list!=0:\n",
    "        if i not in articles:\n",
    "            articles.append(i)\n",
    "            print(recs_filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['use deep learning for image classification']\n",
      "['classify tumors with machine learning']\n",
      "['use xgboost, scikit-learn & ibm watson machine learning apis']\n",
      "['apache spark lab, part 3: machine learning']\n",
      "['putting a human face on machine learning']\n",
      "['overfitting in machine learning: what it is and how to prevent it']\n",
      "['use apache systemml and spark for machine learning']\n",
      "['graph-based machine learning']\n",
      "['python machine learning: scikit-learn tutorial']\n",
      "['deep learning with tensorflow course by big data university']\n",
      "['learn tensorflow and deep learning together and now!']\n",
      "['rapidly build machine learning flows with dsx']\n",
      "['using machine learning to predict baseball injuries']\n",
      "['deep learning trends and an example']\n",
      "['machine learning for everyone']\n",
      "['deep learning from scratch i: computational graphs']\n",
      "['movie recommender system with spark machine learning']\n",
      "['deep learning with data science experience']\n",
      "['ibm watson machine learning: get started']\n",
      "['challenges in deep learning']\n",
      "['awesome deep learning papers']\n",
      "['top 10 machine learning algorithms for beginners']\n",
      "[\"2875    hugo larochelle's neural network & deep learni...\\nName: title, dtype: object\"]\n",
      "['make machine learning a reality for your enterprise']\n",
      "['declarative machine learning']\n",
      "['use the machine learning library']\n",
      "['the 3 kinds of context: machine learning and the art of the frame']\n",
      "['using machine learning to predict value of homes on airbnb']\n",
      "['machine learning exercises in python, part 1']\n",
      "['adoption of machine learning to software failure prediction']\n",
      "['optimization for deep learning highlights in 2017']\n",
      "['using deep learning with keras to predict customer churn']\n",
      "['spark-based machine learning tools for capturing word meanings']\n",
      "['three reasons machine learning models go out of sync']\n",
      "['machine learning and the science of choosing']\n",
      "['deep forest: towards an alternative to deep neural networks']\n",
      "['10 essential algorithms for machine learning engineers']\n",
      "['data structures related to machine learning algorithms']\n",
      "['a dynamic duo – inside machine learning – medium']\n",
      "['ensemble learning to improve machine learning results']\n",
      "['using deep learning to reconstruct high-resolution audio']\n",
      "['when machine learning matters · erik bernhardsson']\n",
      "['the machine learning database']\n",
      "['ml algorithm != learning machine']\n",
      "['what is machine learning?']\n",
      "['modern machine learning algorithms']\n",
      "['machine learning for the enterprise.']\n",
      "['top 10 machine learning use cases: part 1']\n",
      "['using machine learning to predict parking difficulty']\n",
      "['artificial intelligence, ethically speaking – inside machine learning – medium']\n",
      "['essentials of machine learning algorithms (with python and r codes)']\n",
      "['the power of machine learning in spark']\n",
      "['top 20 r machine learning and data science packages']\n",
      "['8 ways to turn data into value with apache spark machine learning']\n",
      "['improving quality of life with spark-empowered machine learning']\n",
      "['the difference between ai, machine learning, and deep learning?', 'the difference between ai, machine learning, and deep learning?']\n",
      "['apache spark 2.0: machine learning. under the hood and over the rainbow.']\n",
      "['how to get a job in deep learning']\n",
      "['building custom machine learning algorithms with apache systemml']\n",
      "['machine learning for the enterprise']\n",
      "['using bigdl in dsx for deep learning on spark']\n",
      "['3 scenarios for machine learning on multicloud']\n",
      "['deep learning achievements over the past year ']\n",
      "['generalization in deep learning']\n",
      "['10 data science, machine learning and ai podcasts you must listen to']\n",
      "['56594    lifelong (machine) learning: how automation ca...\\nName: title, dtype: object']\n",
      "['watson machine learning for developers']\n",
      "['making sense of the bias / variance trade-off in (deep) reinforcement learning']\n",
      "['building your first machine learning system ']\n",
      "['deep learning, structure and innate priors']\n",
      "['a guide to convolution arithmetic for deep learning']\n",
      "['the two phases of gradient descent in deep learning']\n",
      "['apple, ibm add machine learning to partnership with watson-core ml coupling']\n",
      "['find airbnb deals in portland with machine learning using r']\n",
      "['from local spark mllib model to cloud with watson machine learning']\n",
      "['style transfer experiments with watson machine learning']\n",
      "['build deep learning architectures with neural network modeler']\n",
      "['create a project for watson machine learning in dsx']\n"
     ]
    }
   ],
   "source": [
    "articles=[]\n",
    "for i in range(0,interactions_.shape[0]):\n",
    "    recs_filtered_list=recs_filtered(interactions_[\"title\"][i],['deep','machine'])\n",
    "    if recs_filtered_list!=0:\n",
    "        if interactions_[\"article_id\"][i] not in articles:\n",
    "            articles.append(interactions_[\"article_id\"][i])\n",
    "            print(recs_filtered_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. User-User Based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "      <td>937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330.0</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "      <td>927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1431.0</td>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "      <td>671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1427.0</td>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1364.0</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>1113.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>1119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>984.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>1127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>1266.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     article_id  title  email  user_id\n",
       "0        1429.0    937    937      937\n",
       "1        1330.0    927    927      927\n",
       "2        1431.0    671    671      671\n",
       "3        1427.0    643    643      643\n",
       "4        1364.0    627    627      627\n",
       "..          ...    ...    ...      ...\n",
       "709      1113.0      1      1        1\n",
       "710      1119.0      1      1        1\n",
       "711       984.0      1      1        1\n",
       "712      1127.0      1      1        1\n",
       "713      1266.0      1      1        1\n",
       "\n",
       "[714 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe_interactions=interactions_.groupby('article_id').count().sort_values('user_id', ascending=False).reset_index()\n",
    "describe_interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usamnet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "interactions_['rating'] = np.nan\n",
    "article_ids = set(interactions_.article_id)\n",
    "for id_article in article_ids:\n",
    "    for i in range(0,interactions_.shape[0]):\n",
    "        if interactions_.article_id[i] == id_article:\n",
    "            interactions_['rating'][i] = describe_interactions[describe_interactions.article_id==id_article]['user_id']\n",
    "interactions_.to_csv('Interactions.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_ = pd.read_csv('Interactions.csv')\n",
    "del interactions_['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>email</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430.0</td>\n",
       "      <td>using pixiedust for fast, flexible, and easier...</td>\n",
       "      <td>ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7</td>\n",
       "      <td>1</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1314.0</td>\n",
       "      <td>healthcare python streaming application demo</td>\n",
       "      <td>083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b</td>\n",
       "      <td>2</td>\n",
       "      <td>614.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1429.0</td>\n",
       "      <td>use deep learning for image classification</td>\n",
       "      <td>b96a4f2e92d8572034b1e9b28f9ac673765cd074</td>\n",
       "      <td>3</td>\n",
       "      <td>937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.0</td>\n",
       "      <td>ml optimization using cognitive assistant</td>\n",
       "      <td>06485706b34a5c9bf2a0ecdac41daf7e7654ceb7</td>\n",
       "      <td>4</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1276.0</td>\n",
       "      <td>deploy your python model as a restful api</td>\n",
       "      <td>f01220c46fc92c6e6b161b1849de11faacd7ccb2</td>\n",
       "      <td>5</td>\n",
       "      <td>347.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0      1430.0  using pixiedust for fast, flexible, and easier...   \n",
       "1      1314.0       healthcare python streaming application demo   \n",
       "2      1429.0         use deep learning for image classification   \n",
       "3      1338.0          ml optimization using cognitive assistant   \n",
       "4      1276.0          deploy your python model as a restful api   \n",
       "\n",
       "                                      email  user_id  rating  \n",
       "0  ef5f11f77ba020cd36e1105a00ab868bbdbf7fe7        1   336.0  \n",
       "1  083cbdfa93c8444beaa4c5f5e0f5f9198e4f9e0b        2   614.0  \n",
       "2  b96a4f2e92d8572034b1e9b28f9ac673765cd074        3   937.0  \n",
       "3  06485706b34a5c9bf2a0ecdac41daf7e7654ceb7        4   382.0  \n",
       "4  f01220c46fc92c6e6b161b1849de11faacd7ccb2        5   347.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user-by-item matrix\n",
    "user_by_article = interactions_.groupby(['user_id', 'article_id'])['rating'].max().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n",
      "5149\n"
     ]
    }
   ],
   "source": [
    "print(user_by_article.shape[1])\n",
    "print(user_by_article.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  43.,  109.,  151.,  268.,  310.,  329.,  346.,  390.,  494.,\n",
       "        525.,  585.,  626.,  668.,  732.,  768.,  910.,  968.,  981.,\n",
       "       1052., 1170., 1183., 1185., 1232., 1293., 1305., 1363., 1368.,\n",
       "       1391., 1400., 1406., 1427., 1429., 1430., 1431., 1436., 1439.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(user_by_article.loc[1][user_by_article.loc[1].isnull() == False].index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interactions_[interactions_.user_id==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(interactions_[interactions_.user_id==1 & interactions_.article_id.isin([  43.,  109.,  151.,  268.,  310.,  329.,  346.,  390.,  494.,\n",
    "        525.,  585.,  626.,  668.,  732.,  768.,  910.,  968.,  981.,\n",
    "       1052., 1170., 1183., 1185., 1232., 1293., 1305., 1363., 1368.,\n",
    "       1391., 1400., 1406., 1427., 1429., 1430., 1431., 1436., 1439.])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with users and corresponding movies seen\n",
    "\n",
    "def articles_watched(user_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    OUTPUT:\n",
    "    articles - an array of articles the user has watched\n",
    "    '''\n",
    "    articles = np.array(user_by_article.loc[user_id][user_by_article.loc[user_id].isnull() == False].index.values)\n",
    "    \n",
    "    i=0\n",
    "    temp=[]\n",
    "    while i < len(articles):\n",
    "        temp.append(articles[i])\n",
    "        i += 1\n",
    "    articles=temp\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "def create_user_article_dict():\n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: articles_seen - a dictionary where each key is a user_id and the value is an array of article_ids\n",
    "    \n",
    "    Creates the articles_seen dictionary\n",
    "    '''\n",
    "    n_users = user_by_article.shape[0]\n",
    "    articles_seen = {}\n",
    "\n",
    "    for user1 in range(1, n_users+1):\n",
    "        \n",
    "        # assign list of movies to each user key\n",
    "        articles_seen[user1] = articles_watched(user1)\n",
    "    \n",
    "    return articles_seen\n",
    "    \n",
    "articles_seen = create_user_article_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove individuals who have watched 2 or fewer articles - don't have enough data to make recs\n",
    "\n",
    "def create_articles_to_analyze(articles_seen, lower_bound=2):\n",
    "    '''\n",
    "    INPUT:  \n",
    "    articles_seen - a dictionary where each key is a user_id and the value is an array of articles_ids\n",
    "    lower_bound - (an int) a user must have more movies seen than the lower bound to be added to the articles_to_analyze dictionary\n",
    "\n",
    "    OUTPUT: \n",
    "    articles_to_analyze - a dictionary where each key is a user_id and the value is an array of article_ids\n",
    "    \n",
    "    The articles_seen and articles_to_analyze dictionaries should be the same except that the output dictionary has removed \n",
    "    \n",
    "    '''\n",
    "    articles_to_analyze = {}\n",
    "    \n",
    "    \n",
    "    user=np.array( tuple(articles_seen.keys()) )\n",
    "    articles = np.array( tuple(articles_seen.values()) )\n",
    "    \n",
    "    i=0\n",
    "    temp=[]\n",
    "    while i < len(articles):\n",
    "        j = 0\n",
    "        temp=[]\n",
    "        while j < len(articles[i]):\n",
    "            temp.append(articles[i][j])\n",
    "            j += 1\n",
    "        articles_to_analyze[user[i]]=temp\n",
    "        i += 1\n",
    "    \n",
    "    #for user, articles in articles_seen.items():\n",
    "        #if len(articles) > lower_bound:\n",
    "            #articles_to_analyze[user] = articles\n",
    "    return articles_to_analyze\n",
    "\n",
    "articles_to_analyze = create_articles_to_analyze(articles_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5149\n",
      "36\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "# Run the tests below to check that your articles_to_analyze matches the solution\n",
    "print(len(articles_to_analyze)) \n",
    "print(len(articles_to_analyze[1]))\n",
    "print(len(articles_to_analyze[8]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the correlation between the matching ratings between the two users\n",
    "    '''\n",
    "    # Pull movies for each user\n",
    "    articles1 = articles_to_analyze[user1]\n",
    "    articles2 = articles_to_analyze[user2]\n",
    "    \n",
    "    \n",
    "    # Find Similar Movies\n",
    "    sim_movs = np.intersect1d(articles1, articles2, assume_unique=True)\n",
    "    \n",
    "    # Calculate correlation between the users\n",
    "    df = user_by_article.loc[(user1, user2), sim_movs]\n",
    "    corr = df.transpose().corr().iloc[0,1]\n",
    "    \n",
    "    return corr #return the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "nan\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(compute_correlation(2,2))\n",
    "print(round(compute_correlation(2,66), 2))\n",
    "print(np.isnan(compute_correlation(2,104)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correlation the spread in some ratings was zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1427.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which articles did both user 2 and user 104 see?\n",
    "set_2 = set(articles_to_analyze[2])\n",
    "set_104 = set(articles_to_analyze[104])\n",
    "set_2.intersection(set_104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article_id\n",
      "1427.0    643.0\n",
      "Name: 2, dtype: float64\n",
      "article_id\n",
      "1427.0    643.0\n",
      "Name: 104, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# What were the ratings for each user on those articles?\n",
    "print(user_by_article.loc[2, set_2.intersection(set_104)])\n",
    "print(user_by_article.loc[104, set_2.intersection(set_104)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_euclidean_dist(user1, user2):\n",
    "    '''\n",
    "    INPUT\n",
    "    user1 - int user_id\n",
    "    user2 - int user_id\n",
    "    OUTPUT\n",
    "    the euclidean distance between user1 and user2\n",
    "    '''\n",
    "    # Pull movies for each user\n",
    "    articles1 = articles_to_analyze[user1]\n",
    "    articles2 = articles_to_analyze[user2]\n",
    "    \n",
    "    \n",
    "    # Find Similar Movies\n",
    "    sim_movs = np.intersect1d(articles1, articles2, assume_unique=True)\n",
    "    \n",
    "    # Calculate euclidean distance between the users\n",
    "    df = user_by_article.loc[(user1, user2), sim_movs]\n",
    "    dist = np.linalg.norm(df.loc[user1] - df.loc[user2])\n",
    "    \n",
    "    return dist #return the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(compute_euclidean_dist(2,2))\n",
    "print(round(compute_euclidean_dist(2,66), 2))\n",
    "print(np.isnan(compute_euclidean_dist(2,104)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# problem \n",
    "\n",
    "I tried to create a table to calculate the distance, but the values appear either 0 or nan and there are some values that have the fail result like for user2 is:\n",
    "\n",
    "[7,18,25,29,39,47,53,62,84,93,99,101,106,116,123,124,127,128,130,141,142,147,161,162,174,175,177,179,191,201.....]\n",
    "\n",
    "and I overlooked this problem by doing try, except.\n",
    "\n",
    "Please, solution You are expected to reply, thanking you for your cooperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usamnet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>eucl_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>2</td>\n",
       "      <td>5145</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5144</th>\n",
       "      <td>2</td>\n",
       "      <td>5146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5145</th>\n",
       "      <td>2</td>\n",
       "      <td>5147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5146</th>\n",
       "      <td>2</td>\n",
       "      <td>5148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5147</th>\n",
       "      <td>2</td>\n",
       "      <td>5149</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user1  user2  eucl_dist\n",
       "0         2      1        0.0\n",
       "1         2      3        0.0\n",
       "2         2      4        0.0\n",
       "3         2      5        0.0\n",
       "4         2      6        0.0\n",
       "...     ...    ...        ...\n",
       "5143      2   5145        0.0\n",
       "5144      2   5146        0.0\n",
       "5145      2   5147        0.0\n",
       "5146      2   5148        0.0\n",
       "5147      2   5149        0.0\n",
       "\n",
       "[5148 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = []\n",
    "for user1 in list(np.unique(interactions_.user_id)):\n",
    "    if user1 != 2:\n",
    "        users.append(user1)\n",
    " \n",
    "#list of user1, user2, eucl_dist \n",
    "user1 = np.nan\n",
    "user2 = np.unique(users)\n",
    "eucl_dist = np.nan\n",
    "  \n",
    "# dictionary of lists  \n",
    "dict = {'user1': user1, 'user2': user2, 'eucl_dist': eucl_dist}  \n",
    "    \n",
    "df_dists = pd.DataFrame(dict) \n",
    "\n",
    "df_dists['user1'] = 2\n",
    "\n",
    "for i in range(0,df_dists.shape[0]):\n",
    "    try:\n",
    "        df_dists['eucl_dist'][i] = compute_euclidean_dist(2,int(df_dists['user2'][i]))\n",
    "    except:\n",
    "        pass\n",
    "     \n",
    "df_dists  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5148\n",
       "Name: eucl_dist, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dists.eucl_dist.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(user):\n",
    "    users = []\n",
    "    for user1 in list(np.unique(interactions_.user_id)):\n",
    "        if user1 != user:\n",
    "            users.append(user1)\n",
    "    #list of user1, user2, eucl_dist \n",
    "    user1 = np.nan\n",
    "    user2 = np.unique(users)\n",
    "    eucl_dist = np.nan\n",
    "    \n",
    "    # dictionary of lists  \n",
    "    dict = {'user1': user1, 'user2': user2, 'eucl_dist': eucl_dist}  \n",
    "    df_dists = pd.DataFrame(dict) \n",
    "    \n",
    "    df_dists['user1'] = user\n",
    "    \n",
    "    for i in range(0,df_dists.shape[0]):\n",
    "        try:\n",
    "            df_dists['eucl_dist'][i] = compute_euclidean_dist(user,df_dists['user2'][i])\n",
    "        except:\n",
    "            pass\n",
    "    return df_dists\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_neighbors(user):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) the user_id of the individual you want to find the closest users\n",
    "    OUTPUT:\n",
    "        closest_neighbors - an array of the id's of the users sorted from closest to farthest away\n",
    "    '''\n",
    "    # I treated ties as arbitrary and just kept whichever was easiest to keep using the head method\n",
    "    # You might choose to do something less hand wavy\n",
    "    df_dists = calculate_distance(user)\n",
    "    closest_users = df_dists[df_dists['user1']==user].sort_values(by='eucl_dist').iloc[1:]['user2']\n",
    "    closest_neighbors = np.array(closest_users)\n",
    "    \n",
    "    return closest_neighbors\n",
    "    \n",
    "    \n",
    "    \n",
    "def articles_liked(user_id, min_rating=7):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    min_rating - the minimum rating considered while still a movie is still a \"like\" and not a \"dislike\"\n",
    "    OUTPUT:\n",
    "    movies_liked - an array of movies the user has watched and liked\n",
    "    '''\n",
    "    articles_liked = np.array(interactions_.query('user_id == @user_id and rating > (@min_rating -1)')['article_id'])\n",
    "    \n",
    "        \n",
    "    i=0\n",
    "    articles_liked_temp=[]\n",
    "    while i < len(articles_liked):\n",
    "        articles_liked_temp.append(articles_liked[i])\n",
    "        i += 1\n",
    "    articles_liked=articles_liked_temp\n",
    "    \n",
    "    return articles_liked\n",
    "\n",
    "\n",
    "def article_names(article_ids):\n",
    "    '''\n",
    "    INPUT\n",
    "    article_ids - a list of article_ids\n",
    "    OUTPUT\n",
    "    articles - a list of article names associated with the article_ids\n",
    "    \n",
    "    '''\n",
    "    article_lst = list(articles_[articles_['article_id'].isin(article_ids)]['doc_full_name'])\n",
    "   \n",
    "    return article_lst\n",
    "    \n",
    "    \n",
    "def make_recommendations(user, num_recs=10):\n",
    "    '''\n",
    "    INPUT:\n",
    "        user - (int) a user_id of the individual you want to make recommendations for\n",
    "        num_recs - (int) number of movies to return\n",
    "    OUTPUT:\n",
    "        recommendations - a list of movies - if there are \"num_recs\" recommendations return this many\n",
    "                          otherwise return the total number of recommendations available for the \"user\"\n",
    "                          which may just be an empty list\n",
    "    '''\n",
    "    # I wanted to make recommendations by pulling different movies than the user has already seen\n",
    "    # Go in order from closest to farthest to find movies you would recommend\n",
    "    # I also only considered movies where the closest user rated the movie as a 9 or 10\n",
    "    \n",
    "    # movies_seen by user (we don't want to recommend these)\n",
    "    articles_seen = articles_watched(user)\n",
    "    closest_neighbors = find_closest_neighbors(user)\n",
    "    \n",
    "    # Keep the recommended movies here\n",
    "    recs = []#np.array([])\n",
    "    \n",
    "    # Go through the neighbors and identify movies they like the user hasn't seen\n",
    "    for neighbor in closest_neighbors:\n",
    "        neighbs_likes = articles_liked(neighbor)\n",
    "        #Obtain recommendations for each neighbor\n",
    "        #new_recs = np.setdiff1d(neighbs_likes, articles_seen, assume_unique=True)\n",
    "        new_recs = list(set(neighbs_likes).symmetric_difference(articles_seen))\n",
    "        # Update recs with new recs\n",
    "        for i in new_recs:\n",
    "            if i not in recs:\n",
    "                recs.append(i) \n",
    "        #recs = np.unique(np.concatenate([new_recs, recs], axis=0))\n",
    "        \n",
    "        # If we have enough recommendations exit the loop\n",
    "        if len(recs) > num_recs-1:\n",
    "            break\n",
    "    # Pull movie titles using movie ids\n",
    "    recommendations = article_names(recs)\n",
    "    \n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def all_recommendations(num_recs=10):\n",
    "    '''\n",
    "    INPUT \n",
    "        num_recs (int) the (max) number of recommendations for each user\n",
    "    OUTPUT\n",
    "        all_recs - a dictionary where each key is a user_id and the value is an array of recommended movie titles\n",
    "    '''\n",
    "    \n",
    "    # All the users we need to make recommendations for\n",
    "    users = np.unique(interactions_.user_id)\n",
    "    n_users = len(users)\n",
    "    \n",
    "    #Store all recommendations in this dictionary\n",
    "    all_recs = {}\n",
    "    \n",
    "    # Make the recommendations for each user\n",
    "    for user in users:\n",
    "        all_recs[user] = make_recommendations(user, num_recs)\n",
    "    \n",
    "    return all_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usamnet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How to map USA rivers using ggplot2',\n",
       " 'Simple Graphing with IPython and\\xa0Pandas',\n",
       " 'Web Picks (week of 23 January 2017)',\n",
       " 'Using Deep Learning to Reconstruct High-Resolution Audio']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_recommendations(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usamnet\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "all_recs = all_recommendations(10)\n",
    "all_recs[2]\n",
    "\n",
    "# Users without recs\n",
    "users_without_recs = []\n",
    "for user, movie_recs in all_recs.items():\n",
    "    if len(movie_recs) == 0:\n",
    "        users_without_recs.append(user)\n",
    "    \n",
    "len(users_without_recs)\n",
    "\n",
    "# NaN euclidean distance values\n",
    "df_dists['eucl_dist'].isnull().sum()\n",
    "\n",
    "# Users with fewer than 10 recs\n",
    "users_with_less_than_10recs = []\n",
    "for user, movie_recs in all_recs.items():\n",
    "    if len(movie_recs) < 10:\n",
    "        users_with_less_than_10recs.append(user)\n",
    "    \n",
    "len(users_with_less_than_10recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Content Based Recommendations (EXTRA - NOT REQUIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\usamnet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\usamnet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\usamnet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(['punkt', 'wordnet'])\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithms', 'analysis', 'analytics', 'analyze', 'apache', 'api', 'app', 'application', 'applications', 'apps', 'bluemix', 'build', 'building', 'business', 'catalog', 'cloud', 'cloudant', 'compose', 'conference:', 'couchdb', 'create', 'customer:', 'dashdb', 'data', 'database', 'databases', 'datalayer', 'day', 'deep', 'dsx', 'elasticsearch', 'experience', 'first', 'geospatial', 'get', 'getting', 'graph', 'guide', 'ibm', 'index', 'introducing', 'json', 'jupyter', 'lab', 'learning', 'library', 'load', 'machine', 'making', 'maven:', 'medium', 'metrics', 'models', 'mongodb', 'moving', 'mysql', 'neural', 'new', 'node.js', 'notebook', 'notebooks', 'offline', 'open', 'part', 'postgresql', 'predict', 'python', 'queries', 'query', 'redis', 'rethinkdb', 'rstudio', 'science', 'search', 'service', 'seven', 'simple', 'spark', 'sql', 'started', 'storage', 'tutorial', 'use', 'using', 'visualization', 'warehouse', 'watson', 'web', 'week']\n"
     ]
    }
   ],
   "source": [
    "word_series = pd.Series(' '.join(articles_['doc_full_name']).lower().split())\n",
    "top_words = word_series[~word_series.isin(stopwords.words(\"english\"))].value_counts()[:100]\n",
    "top_words_names = np.unique(np.array(top_words.index))\n",
    "filtered_words_names = []\n",
    "for i in top_words_names:\n",
    "    if i not in ['&', '-', '2016)', '2017)','–','r','1', '10', '2', '3','—']:\n",
    "        filtered_words_names.append(i)\n",
    "print(filtered_words_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and another\n",
    "# Function to split and return values for columns\n",
    "def split_words(val):\n",
    "    try:\n",
    "        if val.find(word) >-1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "\n",
    "# Apply function for each genre\n",
    "for word in filtered_words_names:        \n",
    "    articles_[word] = articles_['doc_description'].apply(split_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithms</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analytics</th>\n",
       "      <th>analyze</th>\n",
       "      <th>apache</th>\n",
       "      <th>api</th>\n",
       "      <th>app</th>\n",
       "      <th>application</th>\n",
       "      <th>applications</th>\n",
       "      <th>apps</th>\n",
       "      <th>...</th>\n",
       "      <th>started</th>\n",
       "      <th>storage</th>\n",
       "      <th>tutorial</th>\n",
       "      <th>use</th>\n",
       "      <th>using</th>\n",
       "      <th>visualization</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>watson</th>\n",
       "      <th>web</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1051 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      algorithms  analysis  analytics  analyze  apache  api  app  application  \\\n",
       "0              0         0          0        0       0    0    0            0   \n",
       "1              0         1          0        0       0    0    0            0   \n",
       "2              0         0          0        0       0    0    0            0   \n",
       "3              0         0          0        0       0    0    0            0   \n",
       "4              0         0          0        0       0    0    0            0   \n",
       "...          ...       ...        ...      ...     ...  ...  ...          ...   \n",
       "1051           0         0          0        0       0    0    0            0   \n",
       "1052           0         0          0        0       0    0    0            0   \n",
       "1053           1         0          0        0       0    0    0            0   \n",
       "1054           0         0          0        1       0    0    0            0   \n",
       "1055           0         0          0        0       0    0    0            0   \n",
       "\n",
       "      applications  apps  ...  started  storage  tutorial  use  using  \\\n",
       "0                0     0  ...        0        0         0    0      1   \n",
       "1                0     0  ...        0        0         0    0      0   \n",
       "2                0     0  ...        0        0         0    0      0   \n",
       "3                0     0  ...        0        1         0    0      0   \n",
       "4                0     0  ...        0        0         0    0      1   \n",
       "...            ...   ...  ...      ...      ...       ...  ...    ...   \n",
       "1051             0     0  ...        0        0         0    1      0   \n",
       "1052             0     0  ...        0        0         0    0      0   \n",
       "1053             0     0  ...        0        0         0    0      0   \n",
       "1054             0     0  ...        0        0         0    1      0   \n",
       "1055             0     0  ...        0        0         0    1      0   \n",
       "\n",
       "      visualization  warehouse  watson  web  week  \n",
       "0                 0          0       0    0     0  \n",
       "1                 0          0       0    0     0  \n",
       "2                 0          0       0    0     1  \n",
       "3                 0          0       0    0     0  \n",
       "4                 0          0       0    0     0  \n",
       "...             ...        ...     ...  ...   ...  \n",
       "1051              0          0       0    0     0  \n",
       "1052              0          0       0    0     0  \n",
       "1053              0          0       0    0     0  \n",
       "1054              0          0       0    0     0  \n",
       "1055              0          0       0    0     0  \n",
       "\n",
       "[1051 rows x 89 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_.iloc[:,5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset so article_content is only using the dummy variables for each title content dummy columns\n",
    "article_content = np.array(articles_.iloc[:,5:])\n",
    "\n",
    "# Take the dot product to obtain a movie x article matrix of similarities\n",
    "dot_prod_articles = article_content.dot(np.transpose(article_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n",
      "1051\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# create checks for the dot product matrix\n",
    "print(dot_prod_articles.shape[0])\n",
    "print(dot_prod_articles.shape[1])\n",
    "print(dot_prod_articles[0, 0] == np.max(dot_prod_articles[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DataLayer Conference: Boost the performance of your distributed database']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['“Schemas” in CouchDB',\n",
       " 'Build an iOS 8 App with Bluemix and the MobileFirst Platform for            iOS',\n",
       " 'Building an Ordering Application with Watson AI and PostgreSQL: Part II',\n",
       " 'Cleaning the swamp: Turn your data lake into a source of crystal-clear insight']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_articles(article_id):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_id - a article_id \n",
    "    OUTPUT\n",
    "    similar_movies - an array of the most similar articles by doc_full_name\n",
    "    '''\n",
    "    # find the row of each article id\n",
    "    article_idx = np.where(articles_['article_id'] == article_id)[0][0]\n",
    "    \n",
    "    # find the most similar article indices - to start I said they need to be the same for all content\n",
    "    similar_idxs = np.where(dot_prod_articles[article_idx] == np.max(dot_prod_articles[article_idx]))[0]\n",
    "    \n",
    "    # pull the article doc_full_name based on the indices\n",
    "    similar_articles = np.array(articles_.iloc[similar_idxs, ]['doc_full_name'])\n",
    "    \n",
    "    return similar_articles\n",
    "\n",
    "\n",
    "cur_article=list(articles_['doc_full_name'][articles_['article_id']==3])\n",
    "print(cur_article)\n",
    "\n",
    "rec_articles = find_similar_articles(3)\n",
    "new_recs = list(set(rec_articles).symmetric_difference(cur_article))\n",
    "new_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
